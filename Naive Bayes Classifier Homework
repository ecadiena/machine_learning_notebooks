{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ecadiena/machine_learning_notebooks/blob/main/Naive%20Bayes%20Classifier%20Homework\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0V6Cw-35lVs"
      },
      "outputs": [],
      "source": [
        "###\n",
        "### Code imports.\n",
        "###\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveBayesClassifier:\n",
        "  def __init__(self, smoothing_parameter):\n",
        "    '''\n",
        "    Input a smoothing parameter beta.\n",
        "    '''\n",
        "    self.smoothing_parameter = smoothing_parameter\n",
        "\n",
        "  def fit(self, X_train, y_train):\n",
        "    '''\n",
        "    Each row in X_train respresents a sentence. \n",
        "    X_train[i][0] is an indicator of the word \"free\".\n",
        "    X_train[i][1] is an indicator of the word \"dear\".\n",
        "    X_train[i][2] is an indicator of the word \"sincerely\".\n",
        "\n",
        "    Each row in y_train represents the corresponding classification of each row\n",
        "    in X_train. 0 = not spam, 1 = spam.\n",
        "    '''\n",
        "\n",
        "    # method to perform laplace smoothing\n",
        "    def laplace_smoothing(target, total):\n",
        "      return (target + self.smoothing_parameter) / (total + self.smoothing_parameter * 2)\n",
        "\n",
        "    spamCount = 0\n",
        "    noSpamCount = 0\n",
        "    \n",
        "    freeSpam = 0\n",
        "    dearSpam = 0\n",
        "    sincerelySpam = 0\n",
        "\n",
        "    noFreeSpam = 0\n",
        "    noDearSpam = 0\n",
        "    noSincerelySpam = 0\n",
        "\n",
        "    freeNoSpam = 0\n",
        "    dearNoSpam = 0\n",
        "    sincerelyNoSpam = 0\n",
        "\n",
        "    noFreeNoSpam = 0\n",
        "    noDearNoSpam = 0\n",
        "    noSincerelyNoSpam = 0\n",
        "\n",
        "    y = len(y_train)\n",
        "    x = len(X_train)\n",
        "\n",
        "    ### Calculate prior probabilities (no smoothing).\n",
        "    for i in range(y):  \n",
        "      if y_train[i] == 1:\n",
        "        spamCount += 1\n",
        "      if y_train[i] == 0:\n",
        "        noSpamCount += 1\n",
        "    self.prob_spam = (spamCount / y) \n",
        "    self.prob_nospam = (noSpamCount / y) \n",
        "\n",
        "    ### Calculate conditional probabilities (use smoothing).\n",
        "    for i in range(x):\n",
        "      for j in range(i):\n",
        "        # free indicator\n",
        "        if j == 0: \n",
        "          if X_train[i][j] == 1 and y_train[i] == 1:\n",
        "            freeSpam += 1\n",
        "          if X_train[i][j] == 0 and y_train[i] == 1:\n",
        "            noFreeSpam += 1\n",
        "          if X_train[i][j] == 1 and y_train[i] == 0:\n",
        "            freeNoSpam +=1          \n",
        "          if X_train[i][j] == 0 and y_train[i] == 0:\n",
        "            noFreeNoSpam += 1\n",
        "        # dear indicator\n",
        "        if j == 1:\n",
        "          if X_train[i][j] == 1 and y_train[i] == 1:\n",
        "            dearSpam += 1\n",
        "          if X_train[i][j] == 0 and y_train[i] == 1:\n",
        "            noDearSpam += 1\n",
        "          if X_train[i][j] == 1 and y_train[i] == 0:\n",
        "            dearNoSpam += 1\n",
        "          if X_train[i][j] == 0 and y_train[i] == 0:\n",
        "            noDearNoSpam += 1\n",
        "        # sincerely indicator\n",
        "        if j == 2:\n",
        "          if X_train[i][j] == 1 and y_train[i] == 1:\n",
        "            sincerelySpam += 1\n",
        "          if X_train[i][j] == 0 and y_train[i] == 1:\n",
        "            noSincerelySpam += 1\n",
        "          if X_train[i][j] == 1 and y_train[i] == 0:\n",
        "            sincerelyNoSpam += 1\n",
        "          if X_train[i][j] == 0 and y_train[i] == 0:\n",
        "            noSincerelyNoSpam += 1\n",
        "\n",
        "    self.prob_free_given_spam = laplace_smoothing(freeSpam, spamCount) \n",
        "    self.prob_dear_given_spam = laplace_smoothing(dearSpam, spamCount)\n",
        "    self.prob_sincerely_given_spam = laplace_smoothing(sincerelySpam, spamCount)\n",
        "\n",
        "    self.prob_nofree_given_spam = laplace_smoothing(noFreeSpam, spamCount) \n",
        "    self.prob_nodear_given_spam = laplace_smoothing(noDearSpam, spamCount) \n",
        "    self.prob_nosincerely_given_spam = laplace_smoothing(noSincerelySpam, spamCount) \n",
        "\n",
        "    self.prob_free_given_nospam = laplace_smoothing(freeSpam, noSpamCount) \n",
        "    self.prob_dear_given_nospam = laplace_smoothing(dearSpam, noSpamCount) \n",
        "    self.prob_sincerely_given_nospam = laplace_smoothing(sincerelySpam, noSpamCount) \n",
        "\n",
        "    self.prob_nofree_given_nospam = laplace_smoothing(noFreeNoSpam, noSpamCount)\n",
        "    self.prob_nodear_given_nospam = laplace_smoothing(noDearNoSpam, noSpamCount)\n",
        "    self.prob_nosincerely_given_nospam = laplace_smoothing(noSincerelyNoSpam, noSpamCount)\n",
        "\n",
        "    #print(self.prob_free_given_spam)\n",
        "    #print(self.prob_dear_given_spam)\n",
        "    #print(self.prob_sincerely_given_spam)\n",
        "    #print(self.prob_nofree_given_spam)\n",
        "    #print(self.prob_nodear_given_spam)\n",
        "    #print(self.prob_nosincerely_given_spam)\n",
        "    #print(self.prob_free_given_nospam)\n",
        "    #print(self.prob_dear_given_nospam)\n",
        "    #print(self.prob_sincerely_given_nospam)\n",
        "    #print(self.prob_nofree_given_nospam)\n",
        "    #print(self.prob_nodear_given_nospam)\n",
        "    #print(self.prob_nosincerely_given_nospam)\n",
        "\n",
        "  def predict(self, x_test):\n",
        "    '''\n",
        "    Make a prediction of either spam (1) or not spam (0) for a single test data point x_test.\n",
        "\n",
        "    Return a tuple of form \n",
        "    (prediction of 0 or 1, \n",
        "    numerator [of Bayes Rule] of probability of not spam from 0 to 1, \n",
        "    numerator [of Bayes Rule] of probability of spam from 0 to 1)\n",
        "    '''\n",
        "\n",
        "    # prob_spam = (self.prob_spam * ((self.prob_free_given_spam * self.prob_dear_given_spam * self.prob_sincerely_given_spam) * \n",
        "    #                                   (self.prob_nofree_given_spam * self.prob_nodear_given_spam * self.prob_nosincerely_given_spam)))\n",
        "    # prob_nospam = (self.prob_nospam * ((self.prob_free_given_nospam * self.prob_dear_given_nospam * self.prob_sincerely_given_nospam) * \n",
        "    #                                   (self.prob_nofree_given_nospam * self.prob_nodear_given_nospam * self.prob_nosincerely_given_nospam)))\n",
        "    prob_spam = (self.prob_spam / self.prob_nospam) * (self.prob_spam / len(x_test))\n",
        "    prob_nospam = (self.prob_nospam / self.prob_spam) * (self.prob_nospam / len(x_test))\n",
        "\n",
        "    if prob_spam > prob_nospam:\n",
        "      return (1, prob_nospam, prob_spam)\n",
        "    else:\n",
        "      return (0, prob_nospam, prob_spam)\n",
        "\n"
      ],
      "metadata": {
        "id": "f4LlHG3w5shy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unit_test():\n",
        "  '''\n",
        "  Test your solution.\n",
        "  '''\n",
        "  X_train = np.array([[1,1,1], \n",
        "                      [1,1,0],\n",
        "                      [0,0,0],\n",
        "                      [0,1,0],\n",
        "                      [1,0,1],\n",
        "                      [1,0,1],\n",
        "                      [0,1,0],\n",
        "                      [0,1,1]])\n",
        "  y_train = np.array([ 1, 1, 0, 0, 1, 1, 0, 0 ])\n",
        "  clf = NaiveBayesClassifier(0.001)\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  X_test = np.array([[1,0,0], \n",
        "                     [1,0,1],\n",
        "                     [0,1,1],\n",
        "                     [0,0,1]])\n",
        "  \n",
        "  print('Expected output: ')\n",
        "  print_str = '''\n",
        "  (1, 2.3433589849604016e-05, 0.06251560938671095)\n",
        "  (1, 7.816402345702639e-06, 0.1874219218476719)\n",
        "  (0, 0.09375779298826566, 4.6843769519538096e-05)\n",
        "  (0, 0.03127342578515625, 4.6843769519538096e-05)\n",
        "  '''\n",
        "  print(print_str)\n",
        "\n",
        "  print('Actual output: \\n')\n",
        "  for x_test in X_test:\n",
        "    print(clf.predict(x_test))\n",
        "\n",
        "unit_test()"
      ],
      "metadata": {
        "id": "TjuwxxcY5slT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b73521d-bcfc-4383-c3ed-cf8154621706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected output: \n",
            "\n",
            "  (1, 2.3433589849604016e-05, 0.06251560938671095)\n",
            "  (1, 7.816402345702639e-06, 0.1874219218476719)\n",
            "  (0, 0.09375779298826566, 4.6843769519538096e-05)\n",
            "  (0, 0.03127342578515625, 4.6843769519538096e-05)\n",
            "  \n",
            "Actual output: \n",
            "\n",
            "(0, 0.16666666666666666, 0.16666666666666666)\n",
            "(0, 0.16666666666666666, 0.16666666666666666)\n",
            "(0, 0.16666666666666666, 0.16666666666666666)\n",
            "(0, 0.16666666666666666, 0.16666666666666666)\n"
          ]
        }
      ]
    }
  ]
}